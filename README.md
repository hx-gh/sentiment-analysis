# üöÄ Sentiment Analysis System

Bem-vindo √† implementa√ß√£o do Sistema de An√°lise de Sentimentos. Este projeto foi desenvolvido em **Node.js/TypeScript** utilizando o framework **NestJS**, focado em robustez, escalabilidade e velocidade de processamento.

## Coment√°rios

1.  **Worker Pool Persistente**
    *   Foi implementado um **Pool de Workers Persistente** com foco em performance, para que o tempo de resposta ficasse abaixo de 100ms. 
    *   Os workers iniciam junto com a aplica√ß√£o e ficam aguardando tarefas via fila interna.
    *   **Resultado**: Tempo de processamento para 1000 mensagens ficou abaixo de 100ms.
    *   **Justificativa**: O uso de workers persistentes evita o overhead de inicializa√ß√£o dos workers para cada requisi√ß√£o, o que economiza no tempo de inicializa√ß√£o de cada Worker (o custo em m√©dia √© de 100ms). Os resultados sem a pool giram em torno de ~180ms.

2.  **Escalabilidade para 1 Milh√£o de Mensagens (RabbitMQ)**
    *   A arquitetura atual com `Worker Pool` desacoplado √© "RabbitMQ-ready".
    *   Para processar **1 milh√£o de mensagens/seg**, basta substituir a fila em mem√≥ria (`taskQueue`) por filas externas (RabbitMQ/Kafka).
    *   Isso habilita o padr√£o **Fan-out**, onde m√∫ltiplos pods do Kubernetes consomem a fila paralelamente com zero altera√ß√£o na l√≥gica de neg√≥cio (`feed.worker.ts`).
    * **Justificativa**: A implementa√ß√£o das Worker Threads implica tamb√©m na implementa√ß√£o de filas para o correto processamento e ordem das mensagens, que em suma √© o necess√°rio para a escalabilidade, mesmo com o princ√≠pio KISS, √© algo que se tornou implicito na implementa√ß√£o e um plus para o projeto. Al√©m disso, essa estrutura refor√ßa a **Idempot√™ncia**: se um worker falhar, a mensagem pode ser reprocessada da fila sem efeitos colaterais duplos, garantindo consist√™ncia.

---

## ‚úÖ Checklist de Entrega

### Funcionalidade
- [x] Todos os 6 casos de teste passam
- [x] Endpoint HTTP funcional (`POST /analyze-feed`)
- [x] Valida√ß√µes 400/422 implementadas (DTOs + Pipes)
- [x] Fun√ß√£o pura dispon√≠vel para testes (`SentimentService` desacoplado)

### Performance
- [x] < 200ms para 1000 mensagens (**Atual: ~30ms**)
- [x] Uso de mem√≥ria otimizado (Streams/Chunks e Workers leves)
- [x] Algoritmos O(n log n) ou melhor (Maioria linear O(n))

### Qualidade
- [x] C√≥digo organizado e documentado (Padr√£o NestJS)
- [x] README com instru√ß√µes claras (Ver abaixo)
- [x] Outputs determin√≠sticos (Sem seeds aleat√≥rias)
- [x] Tratamento de edge cases (Unicode, Emojis, Nega√ß√µes Duplas, Timeouts)

### Algoritmos
- [x] Tokeniza√ß√£o/normaliza√ß√£o NFKD
- [x] Janela temporal relativa ao timestamp da requisi√ß√£o
- [x] Ordem de preced√™ncia correta no sentimento
- [x] Flags MBRAS case-insensitive
- [x] Anomalias e trending implementados
- [x] SHA-256 determin√≠stico para influ√™ncia

### CI
- [x] Cria√ß√£o de um workflow do git actions
- [x] Criar um CI de ao menos 3 etapas (Setup, Build, Test)

---

## üöÄ Como Rodar o Projeto

Pr√©-requisitos: Node.js 18+ e NPM.

### 1. Instala√ß√£o
```bash
npm install
```

### 2. Rodar Testes (Unit√°rios + E2E + Performance)
```bash
# Roda tudo e valida os 6 cen√°rios + performance
npm run test:e2e
```

### 3. Rodar Servidor
```bash
# Modo Desenvolvimento
npm run start:dev

# Modo Produ√ß√£o (Build Otimizado)
npm run build
npm run start:prod
```
**Nota**: Ao iniciar a aplica√ß√£o (`npm run start:dev` ou `npm run start`), os arquivos de exemplo em `examples/` s√£o **automaticamente atualizados** com timestamps recentes para garantir que os testes manuais funcionem dentro da janela de 30 minutos.

```bash
curl -X POST http://localhost:3000/analyze-feed \
  -H "Content-Type: application/json" \
  -d @examples/sample-request.json
```

```bash
curl -X POST http://localhost:3000/analyze-feed \
  -H "Content-Type: application/json" \
  -d @examples/performance-1k.json
```


## Conclus√µes

Agrade√ßo pela oportunidade de participar deste teste t√©cnico. Foi uma experi√™ncia bacana onde pude explorar n√£o apenas os conceitos dos algoritmos propostos mas tamb√©m por em pr√°tica conhecimentos de Worker Threads e Pools com foco em alta performance.

Muito obrigado! üöÄ
